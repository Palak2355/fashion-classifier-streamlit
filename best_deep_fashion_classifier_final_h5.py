# -*- coding: utf-8 -*-
"""best_deep_fashion_classifier_final.h5

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11K_Gbc1wzID5zq8ktLftaWVm9wkV6qhN
"""
# --- IMPORT LIBRARIES ---
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import io

# --- LOAD DATA ---
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

# --- PREPROCESSING ---
# Normalize to [0,1]
X_train = X_train.astype("float32") / 255.0
X_test = X_test.astype("float32") / 255.0

# Add channel dimension (CNN input)
X_train = np.expand_dims(X_train, -1)
X_test = np.expand_dims(X_test, -1)

# Split validation set
X_valid = X_train[50000:]
y_valid = y_train[50000:]
X_train = X_train[:50000]
y_train = y_train[:50000]

# One-hot encode labels
y_train_cat = to_categorical(y_train, 10)
y_valid_cat = to_categorical(y_valid, 10)
y_test_cat = to_categorical(y_test, 10)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# --- VISUALIZE SAMPLE ---
plt.figure(figsize=(8, 4))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X_train[i].reshape(28,28), cmap="gray")
    plt.title(class_names[y_train[i]])
    plt.axis('off')
plt.show()

# --- DATA AUGMENTATION ---
datagen = ImageDataGenerator(
    rotation_range=10,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1
)
datagen.fit(X_train)

# --- BUILD CNN ---
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    Conv2D(64, (3,3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    Conv2D(128, (3,3), activation='relu'),
    BatchNormalization(),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# --- EARLY STOPPING ---
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# --- TRAIN MODEL ---
history = model.fit(
    datagen.flow(X_train, y_train_cat, batch_size=128),
    validation_data=(X_valid, y_valid_cat),
    epochs=20,
    callbacks=[early_stop],
    verbose=1
)

# --- EVALUATE ---
test_loss, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)
print(f"âœ… Final Test Accuracy: {test_acc:.4f}")

# --- SAVE MODEL ---
model.save("best_fashion_cnn_fixed.h5")
print("Model saved successfully âœ…")

# --- PLOT TRAINING PERFORMANCE ---
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title("Loss")
plt.legend()
plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping # NEW: For runtime optimization
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
import ipywidgets as widgets
from IPython.display import display, clear_output
from PIL import Image
import io

# Define the 10 class names for Fashion-MNIST
class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Shirt', 'Dress',
               'Coat', 'Sandal', 'Sneaker', 'Bag', 'Ankle boot']

print("All libraries imported successfully!")
print("TensorFlow version:", tf.__version__)
print("--- Check Runtime: GPU should be enabled for fast training! ---")

==============================================================================

# --- Load Data from CSV ---
try:
    train_df = pd.read_csv('/content/drive/MyDrive/ml project/fashion-mnist_train.csv')
    test_df = pd.read_csv('/content/drive/MyDrive/ml project/fashion-mnist_test.csv')
    print(f"\nTraining data shape: {train_df.shape}")
    print(f"Test data shape: {test_df.shape}")
except FileNotFoundError:
    print("\nðŸš¨ ERROR: CSV files not found. Please verify the path or upload files to your session.")
    raise

# Separate Features (X) and Labels (y)
X_train_full_csv = train_df.iloc[:, 1:].values.astype('float32')
y_train_full = train_df.iloc[:, 0].values
X_test_csv = test_df.iloc[:, 1:].values.astype('float32')
y_test = test_df.iloc[:, 0].values

# --- Preprocessing ---
X_train_full = X_train_full_csv / 255.0
X_test = X_test_csv / 255.0

# Split Training data into Train and Validation sets
X_train, X_valid, y_train, y_valid = train_test_split(
    X_train_full, y_train_full, test_size=0.1, random_state=42
)

# Reshape for EDA visualization
X_train_img = X_train.reshape(-1, 28, 28)

plt.figure(figsize=(10, 5))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(X_train_img[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[y_train[i]])
plt.suptitle("Sample Fashion-MNIST Images (Loaded from CSV)")
plt.show()


print("\n--- Training Logistic Regression (LR) ---")
# Increased max_iter for higher accuracy stability
lr_model = LogisticRegression(solver='saga', max_iter=200, random_state=42, n_jobs=-1, verbose=0)
lr_model.fit(X_train, y_train)

# Evaluation
lr_y_pred = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_y_pred)
print(f"âœ… Logistic Regression Test Accuracy: {lr_accuracy:.4f}")
print("Classification Report:")
print(classification_report(y_test, lr_y_pred, target_names=class_names, zero_division=0))

from google.colab import drive
drive.mount('/content/drive')

# --- Prepare data for CNN ---
# Reshape data from (N, 784) to (N, 28, 28, 1) for CNN input
X_train_cnn = X_train.reshape(-1, 28, 28, 1)
X_valid_cnn = X_valid.reshape(-1, 28, 28, 1)
X_test_cnn = X_test.reshape(-1, 28, 28, 1)

# Convert labels to one-hot encoding
y_train_cat = to_categorical(y_train, num_classes=10)
y_valid_cat = to_categorical(y_valid, num_classes=10)


datagen = ImageDataGenerator(
    rotation_range=8,
    zoom_range=0.08,
    width_shift_range=0.08, # Corrected argument
    height_shift_range=0.08 # Corrected argument
)
datagen.fit(X_train_cnn)
print("\nData Augmentation Generator configured.")

# Monitors validation loss and stops training if no improvement after 5 epochs
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)


print("\n--- Training DEEPER Convolutional Neural Network (CNN) ---")

deep_cnn_model = Sequential([
    # Block 1
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    # Block 2
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    # NEW Block 3 (Deeper Architecture - Innovation)
    Conv2D(128, (3, 3), activation='relu'),
    # Note: No Pooling here as the image is already small.

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5), # Regularization
    Dense(10, activation='softmax')
])


deep_cnn_model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

deep_cnn_model.summary()

# Train the model with augmented data, Early Stopping, and MAX 20 Epochs
print("\nStarting DEEPER CNN Training (Max 20 Epochs, will stop early if performance plateaus)...")
history = deep_cnn_model.fit(
    datagen.flow(X_train_cnn, y_train_cat, batch_size=128),
    steps_per_epoch=len(X_train_cnn) // 128,
    epochs=20, # <--- MAX EPOCHS SET TO 20
    validation_data=(X_valid_cnn, y_valid_cat),
    callbacks=[early_stopping], # Early Stopping controls effective runtime
    verbose=1
)

# Evaluation
cnn_loss, cnn_accuracy = deep_cnn_model.evaluate(X_test_cnn, to_categorical(y_test), verbose=0)
print(f"\nâœ… Final DEEPER CNN Test Accuracy: {cnn_accuracy:.4f}")

# Save the best model
model_path = 'best_deep_fashion_classifier_final.h5'
deep_cnn_model.save(model_path)
print(f"Best model saved to {model_path}")

# Use the new model accuracy
deep_cnn_accuracy = cnn_accuracy

# Create a DataFrame for comparison
results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Deep CNN (Optimized)'],
    'Test Accuracy': [lr_accuracy, deep_cnn_accuracy],
    'Notes': ['Linear Baseline', 'Deeper Architecture (Expected 92%+, Robust to custom images)']
})

print("\n--- Model Comparative Analysis ---")
print(results.sort_values(by='Test Accuracy', ascending=False).to_markdown(index=False))

# Load the saved best model for deployment
model_path = 'best_deep_fashion_classifier_final.h5'
try:
    best_model = load_model(model_path)
    print(f"\nLoaded new best model: {model_path}")
except Exception as e:
    print(f"\nFailed to load model for GUI. Ensure training completed successfully. Error: {e}")
    best_model = deep_cnn_model

# 5.1 Define the prediction function (No change needed here)
def predict_image(image_data):
    # Open, convert to grayscale, and resize to 28x28
    img = Image.open(io.BytesIO(image_data)).convert('L')
    img = img.resize((28, 28))

    # Convert to array, normalize, and reshape (1, 28, 28, 1)
    img_array = np.array(img, dtype=np.float32) / 255.0
    img_array = img_array.reshape(1, 28, 28, 1)

    # Predict
    predictions = best_model.predict(img_array, verbose=0)
    predicted_class_index = np.argmax(predictions[0])
    confidence = predictions[0][predicted_class_index] * 100

    return class_names[predicted_class_index], confidence


file_upload = widgets.FileUpload(
    accept='image/*',
    multiple=False,
    description='Upload a Fashion Item Image'
)

output_area = widgets.Output()
button = widgets.Button(description="Classify Item")


def on_classify_button_clicked(b):
    with output_area:
        clear_output(wait=True)
        if not file_upload.value:
            print(" Please upload an image file first.")
            return

        # Extract file data
        uploaded_file_name = next(iter(file_upload.value))
        image_data = file_upload.value[uploaded_file_name]['content']

        try:
            # Display uploaded image
            img = Image.open(io.BytesIO(image_data))
            print(f"Uploaded Image: **{uploaded_file_name}**")
            display(img.resize((150, 150)))

            # Predict
            predicted_label, confidence = predict_image(image_data)

            # Display results
            print("\n--- Prediction Result ---")
            print(f"Predicted Class: **{predicted_label}**")
            print(f"Confidence: **{confidence:.2f}%**")

            # Contextual feedback
            if confidence < 75.0:
                 print("\n Note: Confidence is low. The model may be struggling with the complex color/background of this image versus the simple training images.")

        except Exception as e:
            print(f" An error occurred during classification. Error: {e}")

# 5.4 Link the button to the function
button.on_click(on_classify_button_clicked)

# 5.5 Display the GUI layout
gui_title = widgets.HTML("<h2> Fashion Classifier GUI (Deployment)</h2>")
gui_vbox = widgets.VBox([gui_title, file_upload, button, output_area])

print("\n--- Interact with the GUI below to test the final model ---")
display(gui_vbox)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

deep_cnn_model = Sequential([
    # Block 1
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),

    # Block 2
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    # NEW Block 3 (Deeper Architecture - Innovation)
    Conv2D(128, (3, 3), activation='relu'),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

deep_cnn_model.compile(optimizer='adam',
                       loss='categorical_crossentropy',
                       metrics=['accuracy'])

deep_cnn_model.summary()

deep_cnn_model.save("best_deep_fashion_classifier_final.h5")
print("âœ… Model saved successfully as best_deep_fashion_classifier_final.h5")

